{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('data_nosplit/X.npy')\n",
    "y_onehot = np.load('data_nosplit/y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_CNN_LSTM():\n",
    "    model = Sequential([\n",
    "            TimeDistributed(Conv1D(16,3, activation='relu', padding = \"same\"),input_shape=X.shape[1:]),\n",
    "            TimeDistributed(BatchNormalization()),\n",
    "            TimeDistributed(Dropout(0.5)),\n",
    "            BatchNormalization(),\n",
    "            TimeDistributed(Flatten()),\n",
    "            LSTM(20,unit_forget_bias = 0.5, return_sequences = True),\n",
    "            TimeDistributed(Dense(6,activation='softmax'))])\n",
    "    adam = Adam(lr=0.0001) \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= adam, #variants\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, shuffle = True, test_size = 0.4)\n",
    "X_test2, X_val, y_test2, y_val = train_test_split(X_test, y_test, shuffle = True, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3013: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1259: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1242: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 6605 samples, validate on 2202 samples\n",
      "Epoch 1/100\n",
      "6605/6605 [==============================] - 19s 3ms/step - loss: 1.4275 - acc: 0.5308 - val_loss: 0.8700 - val_acc: 0.8648\n",
      "Epoch 2/100\n",
      "6605/6605 [==============================] - 17s 3ms/step - loss: 0.6992 - acc: 0.8549 - val_loss: 0.4022 - val_acc: 0.9301\n",
      "Epoch 3/100\n",
      "6605/6605 [==============================] - 15s 2ms/step - loss: 0.3957 - acc: 0.9134 - val_loss: 0.2597 - val_acc: 0.9422\n",
      "Epoch 4/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.2947 - acc: 0.9296 - val_loss: 0.2063 - val_acc: 0.9538\n",
      "Epoch 5/100\n",
      "6605/6605 [==============================] - 17s 3ms/step - loss: 0.2409 - acc: 0.9426 - val_loss: 0.1779 - val_acc: 0.9593\n",
      "Epoch 6/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.2163 - acc: 0.9463 - val_loss: 0.1551 - val_acc: 0.9635\n",
      "Epoch 7/100\n",
      "6605/6605 [==============================] - 17s 3ms/step - loss: 0.1938 - acc: 0.9508 - val_loss: 0.1417 - val_acc: 0.9655\n",
      "Epoch 8/100\n",
      "6605/6605 [==============================] - 17s 3ms/step - loss: 0.1793 - acc: 0.9533 - val_loss: 0.1317 - val_acc: 0.9666\n",
      "Epoch 9/100\n",
      "6605/6605 [==============================] - 17s 3ms/step - loss: 0.1654 - acc: 0.9555 - val_loss: 0.1273 - val_acc: 0.9673\n",
      "Epoch 10/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.1566 - acc: 0.9565 - val_loss: 0.1157 - val_acc: 0.9683\n",
      "Epoch 11/100\n",
      "6605/6605 [==============================] - 17s 3ms/step - loss: 0.1457 - acc: 0.9592 - val_loss: 0.1058 - val_acc: 0.9718\n",
      "Epoch 12/100\n",
      "6605/6605 [==============================] - 17s 3ms/step - loss: 0.1407 - acc: 0.9608 - val_loss: 0.1021 - val_acc: 0.9734\n",
      "Epoch 13/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.1333 - acc: 0.9618 - val_loss: 0.0978 - val_acc: 0.9723\n",
      "Epoch 14/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.1239 - acc: 0.9646 - val_loss: 0.0913 - val_acc: 0.9764\n",
      "Epoch 15/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.1181 - acc: 0.9669 - val_loss: 0.0893 - val_acc: 0.9746\n",
      "Epoch 16/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.1141 - acc: 0.9670 - val_loss: 0.0848 - val_acc: 0.9757\n",
      "Epoch 17/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.1076 - acc: 0.9700 - val_loss: 0.0786 - val_acc: 0.9825\n",
      "Epoch 18/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.1025 - acc: 0.9716 - val_loss: 0.0772 - val_acc: 0.9826\n",
      "Epoch 19/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0967 - acc: 0.9729 - val_loss: 0.0719 - val_acc: 0.9837\n",
      "Epoch 20/100\n",
      "6605/6605 [==============================] - 15s 2ms/step - loss: 0.0928 - acc: 0.9745 - val_loss: 0.0684 - val_acc: 0.9841\n",
      "Epoch 21/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0922 - acc: 0.9746 - val_loss: 0.0655 - val_acc: 0.9838\n",
      "Epoch 22/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0856 - acc: 0.9762 - val_loss: 0.0626 - val_acc: 0.9851\n",
      "Epoch 23/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0808 - acc: 0.9778 - val_loss: 0.0598 - val_acc: 0.9853\n",
      "Epoch 24/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0795 - acc: 0.9780 - val_loss: 0.0577 - val_acc: 0.9865\n",
      "Epoch 25/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0744 - acc: 0.9801 - val_loss: 0.0539 - val_acc: 0.9857\n",
      "Epoch 26/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0735 - acc: 0.9803 - val_loss: 0.0520 - val_acc: 0.9870\n",
      "Epoch 27/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0705 - acc: 0.9812 - val_loss: 0.0496 - val_acc: 0.9871\n",
      "Epoch 28/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0671 - acc: 0.9816 - val_loss: 0.0529 - val_acc: 0.9868\n",
      "Epoch 29/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0650 - acc: 0.9827 - val_loss: 0.0465 - val_acc: 0.9858\n",
      "Epoch 30/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0633 - acc: 0.9827 - val_loss: 0.0442 - val_acc: 0.9880\n",
      "Epoch 31/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0644 - acc: 0.9815 - val_loss: 0.0421 - val_acc: 0.9879\n",
      "Epoch 32/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0602 - acc: 0.9835 - val_loss: 0.0412 - val_acc: 0.9887\n",
      "Epoch 33/100\n",
      "6605/6605 [==============================] - 15s 2ms/step - loss: 0.0573 - acc: 0.9836 - val_loss: 0.0437 - val_acc: 0.9879\n",
      "Epoch 34/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0559 - acc: 0.9846 - val_loss: 0.0375 - val_acc: 0.9884\n",
      "Epoch 35/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0546 - acc: 0.9841 - val_loss: 0.0361 - val_acc: 0.9885\n",
      "Epoch 36/100\n",
      "6605/6605 [==============================] - 15s 2ms/step - loss: 0.0555 - acc: 0.9841 - val_loss: 0.0370 - val_acc: 0.9888\n",
      "Epoch 37/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0509 - acc: 0.9855 - val_loss: 0.0348 - val_acc: 0.9888\n",
      "Epoch 38/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0492 - acc: 0.9859 - val_loss: 0.0373 - val_acc: 0.9886\n",
      "Epoch 39/100\n",
      "6605/6605 [==============================] - 15s 2ms/step - loss: 0.0480 - acc: 0.9859 - val_loss: 0.0353 - val_acc: 0.9888\n",
      "Epoch 40/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0471 - acc: 0.9860 - val_loss: 0.0333 - val_acc: 0.9881\n",
      "Epoch 41/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0481 - acc: 0.9855 - val_loss: 0.0320 - val_acc: 0.9890\n",
      "Epoch 42/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0482 - acc: 0.9854 - val_loss: 0.0312 - val_acc: 0.9890\n",
      "Epoch 43/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0475 - acc: 0.9856 - val_loss: 0.0312 - val_acc: 0.9891\n",
      "Epoch 44/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0463 - acc: 0.9858 - val_loss: 0.0316 - val_acc: 0.9890\n",
      "Epoch 45/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0417 - acc: 0.9875 - val_loss: 0.0309 - val_acc: 0.9900\n",
      "Epoch 46/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0433 - acc: 0.9866 - val_loss: 0.0290 - val_acc: 0.9897\n",
      "Epoch 47/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0430 - acc: 0.9870 - val_loss: 0.0298 - val_acc: 0.9900\n",
      "Epoch 48/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0438 - acc: 0.9866 - val_loss: 0.0291 - val_acc: 0.9897\n",
      "Epoch 49/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0404 - acc: 0.9876 - val_loss: 0.0286 - val_acc: 0.9898\n",
      "Epoch 50/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0429 - acc: 0.9866 - val_loss: 0.0285 - val_acc: 0.9895\n",
      "Epoch 51/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0372 - acc: 0.9887 - val_loss: 0.0295 - val_acc: 0.9894\n",
      "Epoch 52/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0385 - acc: 0.9879 - val_loss: 0.0288 - val_acc: 0.9897\n",
      "Epoch 53/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0390 - acc: 0.9878 - val_loss: 0.0273 - val_acc: 0.9899\n",
      "Epoch 54/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0395 - acc: 0.9876 - val_loss: 0.0259 - val_acc: 0.9906\n",
      "Epoch 55/100\n",
      "6605/6605 [==============================] - 17s 3ms/step - loss: 0.0394 - acc: 0.9873 - val_loss: 0.0260 - val_acc: 0.9903\n",
      "Epoch 56/100\n",
      "6605/6605 [==============================] - 16s 2ms/step - loss: 0.0375 - acc: 0.9883 - val_loss: 0.0253 - val_acc: 0.9905\n",
      "Epoch 57/100\n",
      "6605/6605 [==============================] - 18s 3ms/step - loss: 0.0382 - acc: 0.9882 - val_loss: 0.0258 - val_acc: 0.9905\n",
      "Epoch 58/100\n",
      "6605/6605 [==============================] - 18s 3ms/step - loss: 0.0364 - acc: 0.9887 - val_loss: 0.0248 - val_acc: 0.9907\n",
      "Epoch 59/100\n",
      "6605/6605 [==============================] - 19s 3ms/step - loss: 0.0366 - acc: 0.9886 - val_loss: 0.0251 - val_acc: 0.9902\n",
      "Epoch 60/100\n",
      "6605/6605 [==============================] - 19s 3ms/step - loss: 0.0354 - acc: 0.9892 - val_loss: 0.0259 - val_acc: 0.9902\n",
      "Epoch 61/100\n",
      "6605/6605 [==============================] - 21s 3ms/step - loss: 0.0352 - acc: 0.9890 - val_loss: 0.0252 - val_acc: 0.9905\n",
      "Epoch 62/100\n",
      "6605/6605 [==============================] - 23s 3ms/step - loss: 0.0362 - acc: 0.9888 - val_loss: 0.0236 - val_acc: 0.9912\n",
      "Epoch 63/100\n",
      "6605/6605 [==============================] - 24s 4ms/step - loss: 0.0325 - acc: 0.9895 - val_loss: 0.0234 - val_acc: 0.9910\n",
      "Epoch 64/100\n",
      "6605/6605 [==============================] - 23s 3ms/step - loss: 0.0343 - acc: 0.9886 - val_loss: 0.0234 - val_acc: 0.9913\n",
      "Epoch 65/100\n",
      "6605/6605 [==============================] - 20s 3ms/step - loss: 0.0328 - acc: 0.9892 - val_loss: 0.0228 - val_acc: 0.9916\n",
      "Epoch 66/100\n",
      "6605/6605 [==============================] - 22s 3ms/step - loss: 0.0343 - acc: 0.9889 - val_loss: 0.0231 - val_acc: 0.9914\n",
      "Epoch 67/100\n",
      "6605/6605 [==============================] - 23s 4ms/step - loss: 0.0337 - acc: 0.9888 - val_loss: 0.0233 - val_acc: 0.9906\n",
      "Epoch 68/100\n",
      "6605/6605 [==============================] - 23s 4ms/step - loss: 0.0312 - acc: 0.9899 - val_loss: 0.0243 - val_acc: 0.9914\n",
      "Epoch 69/100\n",
      "6605/6605 [==============================] - 21s 3ms/step - loss: 0.0306 - acc: 0.9900 - val_loss: 0.0235 - val_acc: 0.9906\n",
      "Epoch 70/100\n",
      "6605/6605 [==============================] - 21s 3ms/step - loss: 0.0335 - acc: 0.9891 - val_loss: 0.0235 - val_acc: 0.9912\n",
      "Epoch 71/100\n",
      "6605/6605 [==============================] - 20s 3ms/step - loss: 0.0324 - acc: 0.9892 - val_loss: 0.0232 - val_acc: 0.9918\n",
      "Epoch 72/100\n",
      "6605/6605 [==============================] - 24s 4ms/step - loss: 0.0318 - acc: 0.9895 - val_loss: 0.0225 - val_acc: 0.9915\n",
      "Epoch 73/100\n",
      "6605/6605 [==============================] - 25s 4ms/step - loss: 0.0315 - acc: 0.9899 - val_loss: 0.0234 - val_acc: 0.9909\n",
      "Epoch 74/100\n",
      "6605/6605 [==============================] - 21s 3ms/step - loss: 0.0301 - acc: 0.9900 - val_loss: 0.0228 - val_acc: 0.9921- loss: - ETA: 0s - loss: 0.0301 - acc: 0.99\n",
      "Epoch 75/100\n",
      "6605/6605 [==============================] - 23s 3ms/step - loss: 0.0308 - acc: 0.9901 - val_loss: 0.0238 - val_acc: 0.9914\n",
      "Epoch 76/100\n",
      "6605/6605 [==============================] - 19s 3ms/step - loss: 0.0293 - acc: 0.9906 - val_loss: 0.0238 - val_acc: 0.9916\n",
      "Epoch 77/100\n",
      "6605/6605 [==============================] - 21s 3ms/step - loss: 0.0307 - acc: 0.9904 - val_loss: 0.0211 - val_acc: 0.9921\n",
      "Epoch 78/100\n",
      "6605/6605 [==============================] - 22s 3ms/step - loss: 0.0288 - acc: 0.9905 - val_loss: 0.0213 - val_acc: 0.9921\n",
      "Epoch 79/100\n",
      "6605/6605 [==============================] - 20s 3ms/step - loss: 0.0277 - acc: 0.9908 - val_loss: 0.0216 - val_acc: 0.9923\n",
      "Epoch 80/100\n",
      "6605/6605 [==============================] - 22s 3ms/step - loss: 0.0295 - acc: 0.9904 - val_loss: 0.0238 - val_acc: 0.9921\n",
      "Epoch 81/100\n",
      "6605/6605 [==============================] - 23s 3ms/step - loss: 0.0281 - acc: 0.9908 - val_loss: 0.0211 - val_acc: 0.9924\n",
      "Epoch 82/100\n",
      "6605/6605 [==============================] - 25s 4ms/step - loss: 0.0280 - acc: 0.9907 - val_loss: 0.0208 - val_acc: 0.9919\n",
      "Epoch 83/100\n",
      "6605/6605 [==============================] - 20s 3ms/step - loss: 0.0282 - acc: 0.9903 - val_loss: 0.0207 - val_acc: 0.9922\n",
      "Epoch 84/100\n",
      "6605/6605 [==============================] - 19s 3ms/step - loss: 0.0280 - acc: 0.9907 - val_loss: 0.0211 - val_acc: 0.9923\n",
      "Epoch 85/100\n",
      "6605/6605 [==============================] - 19s 3ms/step - loss: 0.0269 - acc: 0.9912 - val_loss: 0.0266 - val_acc: 0.9916\n",
      "Epoch 86/100\n",
      "6605/6605 [==============================] - 20s 3ms/step - loss: 0.0278 - acc: 0.9909 - val_loss: 0.0200 - val_acc: 0.9924\n",
      "Epoch 87/100\n",
      "6605/6605 [==============================] - 20s 3ms/step - loss: 0.0276 - acc: 0.9909 - val_loss: 0.0219 - val_acc: 0.9919\n",
      "Epoch 88/100\n",
      "6605/6605 [==============================] - 21s 3ms/step - loss: 0.0264 - acc: 0.9907 - val_loss: 0.0207 - val_acc: 0.9926\n",
      "Epoch 89/100\n",
      "6605/6605 [==============================] - 20s 3ms/step - loss: 0.0272 - acc: 0.9913 - val_loss: 0.0205 - val_acc: 0.9926\n",
      "Epoch 90/100\n",
      "6605/6605 [==============================] - 22s 3ms/step - loss: 0.0278 - acc: 0.9908 - val_loss: 0.0204 - val_acc: 0.9926\n",
      "Epoch 91/100\n",
      "6605/6605 [==============================] - 20s 3ms/step - loss: 0.0245 - acc: 0.9918 - val_loss: 0.0204 - val_acc: 0.9928\n",
      "Epoch 92/100\n",
      "6605/6605 [==============================] - 21s 3ms/step - loss: 0.0272 - acc: 0.9906 - val_loss: 0.0203 - val_acc: 0.9929\n",
      "Epoch 93/100\n",
      "6605/6605 [==============================] - 20s 3ms/step - loss: 0.0268 - acc: 0.9910 - val_loss: 0.0200 - val_acc: 0.9930\n",
      "Epoch 94/100\n",
      "6605/6605 [==============================] - 21s 3ms/step - loss: 0.0253 - acc: 0.9911 - val_loss: 0.0191 - val_acc: 0.9925\n",
      "Epoch 95/100\n",
      "6605/6605 [==============================] - 21s 3ms/step - loss: 0.0248 - acc: 0.9916 - val_loss: 0.0193 - val_acc: 0.9926\n",
      "Epoch 96/100\n",
      "6605/6605 [==============================] - 20s 3ms/step - loss: 0.0247 - acc: 0.9919 - val_loss: 0.0195 - val_acc: 0.9931\n",
      "Epoch 97/100\n",
      "6605/6605 [==============================] - 21s 3ms/step - loss: 0.0247 - acc: 0.9920 - val_loss: 0.0192 - val_acc: 0.9930\n",
      "Epoch 98/100\n",
      "5408/6605 [=======================>......] - ETA: 3s - loss: 0.0287 - acc: 0.9904"
     ]
    }
   ],
   "source": [
    "model = model_CNN_LSTM()\n",
    "model_history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    \n",
    "    print(str(i+1) + 'th iteration of for loop')\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, shuffle = True, test_size = 0.4)\n",
    "    X_test2, X_val, y_test2, y_val = train_test_split(X_test, y_test, shuffle = True, test_size = 0.5)\n",
    "    model = model_CNN_LSTM()\n",
    "    \n",
    "    filepath= 'data_nosplit\\Weights'+str(i+1)+'\\\\'+ \"val1\" + \"-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    model_history = model.fit(X_train, y_train, epochs=100, batch_size=32, callbacks=callbacks_list, validation_data=(X_val, y_val))\n",
    "    \n",
    "    np.save('data_nosplit\\Weights'+str(i+1)+'\\X_train', X_train)\n",
    "    np.save('data_nosplit\\Weights'+str(i+1)+'\\y_train', y_train)\n",
    "    np.save('data_nosplit\\Weights'+str(i+1)+'\\X_test', X_test2)\n",
    "    np.save('data_nosplit\\Weights'+str(i+1)+'\\y_test', y_test2)\n",
    "    np.save('data_nosplit\\Weights'+str(i+1)+'\\X_val', X_val)\n",
    "    np.save('data_nosplit\\Weights'+str(i+1)+'\\y_val', y_val)\n",
    "    \n",
    "    ## plot accuracy\n",
    "    acc_name = 'data_nosplit/accuracy_plot'+str(i+1)+'.jpg'\n",
    "    loss_name = 'data_nosplit/loss_plot'+str(i+1)+'.jpg'\n",
    "    fig = plt.figure()\n",
    "    plt.plot(model_history.history['acc'])\n",
    "    plt.plot(model_history.history['val_acc'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "    plt.savefig(acc_name)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # # Plot loss\n",
    "    fig = plt.figure()\n",
    "    plt.plot(model_history.history['loss'])\n",
    "    plt.plot(model_history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    plt.savefig(loss_name)\n",
    "    plt.close(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = np.zeros((10,3))\n",
    "df = pd.DataFrame(results, columns=['best_model_path', 'validation_accuracy', 'test_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_model_path'][0] = 'data_nosplit/Weights1/val1-98-0.9963.hdf5'\n",
    "X_test = np.load('data_nosplit/Weights1/X_test.npy')\n",
    "y_test = np.load('data_nosplit/Weights1/y_test.npy')\n",
    "f = model.evaluate(X_test, y_test)\n",
    "df['validation_accuracy'][0] = 99.63\n",
    "df['test_accuracy'][0] = f[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_model_path'][1] = 'data_nosplit/Weights2/val1-99-0.9963.hdf5'\n",
    "X_test = np.load('data_nosplit/Weights2/X_test.npy')\n",
    "y_test = np.load('data_nosplit/Weights2/y_test.npy')\n",
    "f = model.evaluate(X_test, y_test)\n",
    "df['validation_accuracy'][1] = 99.63\n",
    "df['test_accuracy'][1] = f[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_model_path'][2] = 'data_nosplit/Weights3/val1-90-0.9960.hdf5'\n",
    "X_test = np.load('data_nosplit/Weights3/X_test.npy')\n",
    "y_test = np.load('data_nosplit/Weights3/y_test.npy')\n",
    "f = model.evaluate(X_test, y_test)\n",
    "df['validation_accuracy'][2] = 99.60\n",
    "df['test_accuracy'][2] = f[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_model_path'][3] = 'data_nosplit/Weights4/val1-97-0.9971.hdf5'\n",
    "X_test = np.load('data_nosplit/Weights4/X_test.npy')\n",
    "y_test = np.load('data_nosplit/Weights4/y_test.npy')\n",
    "f = model.evaluate(X_test, y_test)\n",
    "df['validation_accuracy'][3] = 99.71\n",
    "df['test_accuracy'][3] = f[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_model_path'][4] = 'data_nosplit/Weights5/val1-99-0.9976.hdf5'\n",
    "X_test = np.load('data_nosplit/Weights5/X_test.npy')\n",
    "y_test = np.load('data_nosplit/Weights5/y_test.npy')\n",
    "f = model.evaluate(X_test, y_test)\n",
    "df['validation_accuracy'][4] = 99.76\n",
    "df['test_accuracy'][4] = f[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_model_path'][5] = 'data_nosplit/Weights6/val1-97-0.9980.hdf5'\n",
    "X_test = np.load('data_nosplit/Weights6/X_test.npy')\n",
    "y_test = np.load('data_nosplit/Weights6/y_test.npy')\n",
    "f = model.evaluate(X_test, y_test)\n",
    "df['validation_accuracy'][5] = 99.80\n",
    "df['test_accuracy'][5] = f[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_model_path'][6] = 'data_nosplit/Weights7/val1-89-0.9958.hdf5'\n",
    "X_test = np.load('data_nosplit/Weights7/X_test.npy')\n",
    "y_test = np.load('data_nosplit/Weights7/y_test.npy')\n",
    "f = model.evaluate(X_test, y_test)\n",
    "df['validation_accuracy'][6] = 99.58\n",
    "df['test_accuracy'][6] = f[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_model_path'][7] = 'data_nosplit/Weights8/val1-88-0.9966.hdf5'\n",
    "X_test = np.load('data_nosplit/Weights8/X_test.npy')\n",
    "y_test = np.load('data_nosplit/Weights8/y_test.npy')\n",
    "f = model.evaluate(X_test, y_test)\n",
    "df['validation_accuracy'][7] = 99.66\n",
    "df['test_accuracy'][7] = f[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_model_path'][8] = 'data_nosplit/Weights9/val1-82-0.9966.hdf5'\n",
    "X_test = np.load('data_nosplit/Weights9/X_test.npy')\n",
    "y_test = np.load('data_nosplit/Weights9/y_test.npy')\n",
    "f = model.evaluate(X_test, y_test)\n",
    "df['validation_accuracy'][8] = 99.66\n",
    "df['test_accuracy'][8] = f[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_model_path'][9] = 'data_nosplit/Weights10/val1-99-0.9966.hdf5'\n",
    "X_test = np.load('data_nosplit/Weights10/X_test.npy')\n",
    "y_test = np.load('data_nosplit/Weights10/y_test.npy')\n",
    "f = model.evaluate(X_test, y_test)\n",
    "df['validation_accuracy'][9] = 99.66\n",
    "df['test_accuracy'][9] = f[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
